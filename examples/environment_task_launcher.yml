train_gpu_ids: "0,1,2,3"
vllm_gpu_ids: "4,5"

vllm_server:
  host: "vllm-server"
  port: 8000
  group_port: 51216
  tensor_parallel_size: 2
  gpu_memory_utilization: 0.9
